{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -m pip install 'scikit-learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From /home/michalula/code/epiCausality/epiCode/PIPELINE_extract_plot_mCG_strands_profiles_bigger_window.ipynb\n",
    "# CGs_all saved as CG_combined_silenced_T_primerES_nCATS_numFWD3852_numRVS2805_padded_reads_silenced_T_primerES_nCATS_mCthresh0.9_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy in dimelo_v2_output\n",
    "# Pipeline executed successfully (analize_forward_reverse_CGs_pipeline function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[nan, nan, nan, ..., nan, nan,  1.],\n",
       "        [nan, nan,  1., ..., nan, nan, nan],\n",
       "        [nan, nan,  1., ..., nan, nan,  1.],\n",
       "        ...,\n",
       "        [nan, nan, nan, ...,  1., nan,  1.],\n",
       "        [nan, nan, nan, ...,  1.,  1., nan],\n",
       "        [nan, nan, nan, ..., nan,  1., nan]]),\n",
       " (6657, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CGs_all_silenced = np.load('/home/michalula/code/epiCausality/epiCode/dimelo_v2_output/CG_combined_silenced_T_primerES_nCATS_numFWD3852_numRVS2805_padded_reads_silenced_T_primerES_nCATS_mCthresh0.9_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy')\n",
    "# Silenced T cells nCATS:\n",
    "# Threshold 0.7 = (\"/home/michalula/code/epiCausality/epiCode/dimelo_v2_output/CG_combined_silenced_T_primerES_nCATS_numFWD4132_numRVS2965_padded_reads_silenced_T_primerES_nCATS_mCthresh0.7_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy\")\n",
    "# # Threshold 0.9 =( '/home/michalula/code/epiCausality/epiCode/dimelo_v2_output/CG_combined_silenced_T_primerES_nCATS_numFWD3852_numRVS2805_padded_reads_silenced_T_primerES_nCATS_mCthresh0.9_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy')\n",
    "\n",
    "CGs_all_silenced, CGs_all_silenced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0]), (6657,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undetided T cells nCATS get lable 0 as CD55 is lowly expressed in silened T cells (~90% of cells should be silenced)\n",
    "y_silenced = np.array([0] * CGs_all_silenced.shape[0])\n",
    "y_silenced, y_silenced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[nan, nan,  1., ..., nan, nan,  1.],\n",
       "        [ 1.,  1.,  1., ...,  1., nan, nan],\n",
       "        [ 1., nan,  1., ...,  1., nan, nan],\n",
       "        ...,\n",
       "        [nan,  1., nan, ...,  1., nan, nan],\n",
       "        [ 1., nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ...,  1., nan, nan]]),\n",
       " (1304, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CGs_all_unedited = np.load(\"/home/michalula/code/epiCausality/epiCode/dimelo_v2_output/CG_combined_unedited_T_primerES_nCATS_numFWD788_numRVS516_padded_reads_unedited_T_primerES_nCATS_mCthresh0.9_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy\")\n",
    "\n",
    "# Unedited T cells nCATS:\n",
    "# Threshold 0.7 =  (\"/home/michalula/code/epiCausality/epiCode/dimelo_v2_output/CG_combined_unedited_T_primerES_nCATS_numFWD1081_numRVS662_padded_reads_unedited_T_primerES_nCATS_mCthresh0.7_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy\")\n",
    "# Threshold 0.9 =(\"/home/michalula/code/epiCausality/epiCode/dimelo_v2_output/CG_combined_unedited_T_primerES_nCATS_numFWD788_numRVS516_padded_reads_unedited_T_primerES_nCATS_mCthresh0.9_t2t_v1_1_chr1:206586162-206586192_2025-02-03.npy\")\n",
    "\n",
    "CGs_all_unedited, CGs_all_unedited.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 1, 1, 1]), (1304,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undetided T cells nCATS get lable 1 as CD55 is highly expressed in undetided T cells\n",
    "y_unedited = np.array([1] * CGs_all_unedited.shape[0])\n",
    "y_unedited, y_unedited.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan,  1., ..., nan, nan,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1., nan, nan],\n",
       "       [ 1., nan,  1., ...,  1., nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ...,  1., nan,  1.],\n",
       "       [nan, nan, nan, ...,  1.,  1., nan],\n",
       "       [nan, nan, nan, ..., nan,  1., nan]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unedited_silenced = np.concatenate((CGs_all_unedited, CGs_all_silenced), axis=0)\n",
    "X_unedited_silenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  67,  120,  785,  110,  845,  343,  750,  542, 1266,  324, 1002,\n",
       "        1122,  118,  735,   20,  525,  327,  637,  392,   55,  790, 1193,\n",
       "         864,  866,  141,   78, 1115,  792, 1041,   43,  854, 1228,  131,\n",
       "          34, 1289,  939, 1245,  301,  398,  865, 1006,  974,  947,   48,\n",
       "         400,  490,  514,  685, 1015,  284,  311,  781,  951,  297,  550,\n",
       "         403, 1183,  300,  566,  164,  762, 1020,  900, 1299,  235,  667,\n",
       "         923,  171,  651,  500,  532,  386,  828,   77, 1133,  763,  608,\n",
       "         996,  991,  734,  840, 1188,  988,  211,  181, 1060,  863,  265,\n",
       "         315, 1030,  476,  904, 1101,  458,  999,  663, 1116, 1149,  192,\n",
       "         273,  270,  628, 1077,  445, 1185,   26,  201,  757,   86,   97,\n",
       "         388,  956,  908, 1284,  468,  140,  250,  459,  700,  283,  633,\n",
       "         295,  704, 1058, 1229,  639, 1021,  835,  889, 1205,  551,  229,\n",
       "         154,  144,  992, 1226,    9,  466,  541, 1287,  530, 1243,  954,\n",
       "         557,  396,  336,  720, 1275,  494,  352,  314,  287, 1218,   72,\n",
       "         615,  630,  517,  985, 1108,  687,  328,  304, 1235,  597,  830,\n",
       "        1054, 1079,  162,  391,  909,  850,  964, 1217,  545,  930,   15,\n",
       "         303, 1198, 1156,  672,  626, 1093,  934, 1273,  465,  779,  684,\n",
       "        1272,  890,  230,  632,  499,  453, 1268,  474,  274,  616,  495,\n",
       "         113,  867,  380,  319,  178,   42,  677,  798,   57,  419,  312,\n",
       "         708, 1197,  596,  711,   45,  970, 1031,  404,   40,  435,  483,\n",
       "          70,  457,  746,  925,  755,  617,  477,  456, 1227,  271,  444,\n",
       "        1117,  872, 1158,   71,  217,  112,  142,  794,  156,  130,  676,\n",
       "         394, 1003,  531,  839, 1175,  967, 1263,  440, 1037,  955, 1024,\n",
       "         588,  894, 1018,  625, 1181,  576,   28,  339, 1208, 1241, 1280,\n",
       "         362,  267,   14,  379,   68, 1139,  773,  957,  593, 1039,  739,\n",
       "        1206,  817, 1036,  100,  573, 1220,  353,  282, 1261,  467, 1005,\n",
       "         128,  563,   24,  345, 1161,  513, 1075, 1071, 1045,    2,  698,\n",
       "         389,  716,  984,  846,  527,  553,  699,  326,  202,  788,   53,\n",
       "         249,  981,  558,  729,  231, 1254,  492,  572,  329,  834,  771,\n",
       "        1083,  577,  847,  797,  451,    4,   54,  620,  943,   66,  549,\n",
       "         148,  606,  851,  937,  998,  448, 1012,  170,  903,  980,  133,\n",
       "        1038,  320,  682, 1119, 1257,  811,   18, 1196,  236, 1152,  251,\n",
       "         317,  665, 1223, 1251,  187,  325,  953,  831, 1084, 1022, 1259,\n",
       "         770,  371,  935,  737,  152, 1016,  290,  117,  646,  603,  277,\n",
       "         948,  539,  234, 1221, 1057,  654,  931,  744, 1100,  589,  310,\n",
       "        1074,  254,  264,  799, 1250, 1014,  732,  420, 1052,  182, 1066,\n",
       "          41,  135,  414,  412,  976,   84,  918,  307,  907,  973,  982,\n",
       "        1194,  560,  891,  559,  224,  200,  674,  344,  795,  442,  873,\n",
       "         977,  645,  268,  919,  511, 1211,  695,  189,  179,  322,  565,\n",
       "         136,  680,  958,  253,  661,  586, 1179,   35,  604,  199,  622,\n",
       "         239, 1043, 1285,  880,  309,  707,   17, 1164,  885, 1195,  238,\n",
       "         472,  544,  899,  105, 1123,  232,  822,  556,  990,  137, 1092,\n",
       "         756,  752,  256,   69,  871,  926, 1128,  489,  512, 1171, 1209,\n",
       "         944, 1070,   83,  176,  710,  432,  552,   88,   25, 1155,  742,\n",
       "         377, 1303,  293,  196,  701,   74,  425,  778,  786,   11,   36,\n",
       "         892,  281,  901,  157,  714,  153, 1153,  659,  650,  809,  370,\n",
       "        1210,  163,  838,  240, 1103,  285,  507,  365,  897,  132, 1095,\n",
       "         441,  214,  213,  138, 1204, 1082,  368,  769,  916,   75, 1182,\n",
       "         367,  640,  686, 1239, 1238,  751,  305, 1146,  330,  416,  906,\n",
       "         618,  832, 1026, 1129,    5,  758,  938,  357, 1112,  454,  206,\n",
       "         802, 1140,   76,  995, 1034,  471, 1234,  382, 1192,  155,  731,\n",
       "        1202, 1172,  175, 1127, 1170,  862, 1278,  759,  124, 1087,  940,\n",
       "         803,  815, 1271,   98,  173,  410,  887,  920, 1044, 1264,  406,\n",
       "         857, 1062, 1295,  102,  355,  174,  924,  760,  561,  740,  692,\n",
       "         111,  712, 1055,  844,  348,  905,  405,   38, 1252,  599,  241,\n",
       "         910,  775, 1142,  726,  610,  624, 1242,  582,  972,  896, 1076,\n",
       "         814,  374,  349,  584,   56,  764,  675,   51,  215,  212,  279,\n",
       "         898,  638, 1130,  564,  521,  485, 1169, 1230, 1240,  479, 1292,\n",
       "        1190, 1010,  842,  823,  275,  280,  598,  600, 1056,  172,  502,\n",
       "         594,  869,  543,   62,  929,  167,  602,  437,  455,  129,  207,\n",
       "         791,  534,  387,  460,  498,  358,  590,  583,  125,  668,   10,\n",
       "         462,  853,  220, 1042,  520,  827, 1246,  579,  165, 1199,  691,\n",
       "        1177,  689,  724,  342,   59,  730,  607,  833,  883, 1102,   29,\n",
       "         491,  703,  134, 1233, 1232,  308,  341,  808,  969, 1008,  611,\n",
       "         634, 1067,  316, 1178,  793, 1212,  860,  439,  715,   12,  335,\n",
       "         261,  629,  473,  276,   79,  787, 1294,  587, 1059, 1154,  888,\n",
       "         655, 1131,  824, 1265,  761,  139,  101,  971,  114,  237,  331,\n",
       "         706,  168, 1269,  570,  952, 1136,  390,  219,  721,  434,   33,\n",
       "         666,  861,  260, 1072,  693,   96,  961, 1068,  464, 1215,  836,\n",
       "         690,  109,  395,  820,  266,  323,  895, 1097, 1267,  921,  272,\n",
       "         783,  766,  673, 1157,  269, 1120,  373,  346, 1064,  868, 1085,\n",
       "         529, 1174,  151,   39,  393,  226,  719,  585,   95,  718, 1288,\n",
       "         183,  826,   99,  540,  407, 1096, 1124, 1298,  688,  218,  184,\n",
       "        1069,  882,  694,  350,  321,  945, 1165, 1040, 1256, 1279,   47,\n",
       "        1135,  723,   85, 1166,  487, 1141,  987,  713, 1236,  104,  536,\n",
       "           6,  488,  481, 1106,   44, 1297,  664,  186, 1017,  227,  401,\n",
       "         660, 1281,  496,  193,  203,  258,  554, 1291,   60,  656,  933,\n",
       "        1147,  248,  433, 1293,  166, 1118, 1200,   22, 1258,  578,  886,\n",
       "          82, 1244,  601, 1249,  302,  983, 1007,  818,  575, 1105, 1013,\n",
       "         122,   63,  470,  843,   80, 1145,  562,  363, 1073,  805,  683,\n",
       "         116,  185,  411,  709, 1201,  332,  143, 1186,  612,  446, 1162,\n",
       "         299,  876,  158,  852,  893,  421,  482, 1134,  621,  911, 1110,\n",
       "         741,  313,  636,  417,   27, 1216, 1023,  150,  875,  874,  243,\n",
       "          91, 1004, 1065,  642,  804,  848,  318,  278,  372,  966,   23,\n",
       "         497, 1086, 1048,  195,  780, 1277,  262,  631,  107,  705,  146,\n",
       "         812,  697,  789,  968, 1270,  784,  428, 1302,  743,  438, 1247,\n",
       "         526,  364,  127,  180,  296,  145,  228,  233, 1189,  994,    8,\n",
       "         748, 1138, 1286,  796, 1125,  205,  605,  418, 1089,  160,  402,\n",
       "         912,  772,  415,  381,  452,  635,  581,  121, 1262,  681]),\n",
       " array([1203,  754,  447,  503, 1253,  878,  149, 1150, 1121, 1090,  294,\n",
       "        1301,  378,  613,  354, 1113, 1081,  292,  696,  915,  255, 1098,\n",
       "         609,  443,  567,  484,  963,  627,  733,   65,  849,  870, 1173,\n",
       "        1050,  510,  949, 1255,  571,  592,  450,  356,  515, 1207, 1282,\n",
       "         580,  106,  340,   93,  877, 1167,  813, 1094,  800, 1160, 1009,\n",
       "         291,  927,   73,  569,  782,   61,  221,  334,  641,   52,   81,\n",
       "        1063,  504,  978,  879, 1237,  807, 1107,  501,  333,    3,  753,\n",
       "         747,  210,  841,  375,  475,  383,  546,  856,  643,  591,  801,\n",
       "         359,  993,  917,  449,  480,  385,  424,  574,  505,  647, 1027,\n",
       "         986,  825,  429,  962,    0,  765,  884,  461, 1053,  188, 1180,\n",
       "           7,   31,  528,  662,  361,   94,  678,   87,   58,  936,  376,\n",
       "         658,  478,  263,  246,  547,  147,  288,  216,  928,  397,  198,\n",
       "         614,  245,  648, 1109,  222,  247, 1231,  960,  644, 1049,  942,\n",
       "        1137,  115,  653,  777,  257, 1000,  997, 1144,  702,   90,  486,\n",
       "         518, 1300,  431,  767, 1214, 1213,  369, 1148,   89, 1078,  965,\n",
       "        1047, 1011, 1046,  463,  506, 1051,  555,  728,   50,  858, 1088,\n",
       "         738,  190, 1080,  427,  623, 1091, 1032,  979,  191,   13,  524,\n",
       "        1025,  423,  774,  252,  855, 1219,  347,  523,  298,  244, 1224,\n",
       "          19,  859,  538, 1248,   64,  409, 1163,  493,  242,  989,  408,\n",
       "        1225,  717,  208,  537,  941,  745,  548, 1296,  123,   30,   49,\n",
       "         159,  950,  902,  108,  829,  516,   32,  422,  519,  126,  522,\n",
       "         722,  225,  535,  508,   92, 1099, 1143, 1126, 1274,  959,  509,\n",
       "         306,  922,  946, 1159,  595,  209,  837,  671,  197,  975,  384,\n",
       "        1104, 1114,  816,  204,  914,  351,  533,  768, 1191,  286,   21,\n",
       "        1151, 1176, 1222, 1019,  776,  649, 1111, 1061, 1001,  169,  821,\n",
       "         338, 1283,  679,  360,  669,  469, 1260, 1184,  810,  430,  223,\n",
       "         177,  103,  736,  657,    1, 1290,  413,  932,  436,  194,  727,\n",
       "         366,  725,  337,  881, 1132,  806,  619,  749, 1033,  259,  399,\n",
       "         670,   16, 1028, 1168, 1035,   37,  819,  119, 1276,  568, 1029,\n",
       "         652,  289,  913, 1187,  161,   46,  426]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(y_unedited.shape[0]), train_size=.75, random_state=16)\n",
    "train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    *shap.datasets.iris(), test_size=0.2, random_state=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.repeat([0,50,100], N_SAMPLES)\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "def predict_reg(f, X, Y):\n",
    "    preds = f.predict(X)\n",
    "    preds012 = np.round(preds / 50) # 100-->2; 50-->1; 0-->0\n",
    "    return np.mean(preds012*50==Y)*100\n",
    "\n",
    "model = LinearRegression().fit(X_train,Y_train)\n",
    "print(\"GLM: {:.2f}%\".format(predict_reg(model, X_test, Y_test)))\n",
    "\n",
    "print(\"####\")\n",
    "model = DecisionTreeRegressor().fit(X_train,Y_train)\n",
    "print(\"Tree: {:.2f}%\".format(predict_reg(model, X_test, Y_test)))\n",
    "print(\"####\")\n",
    "model = RandomForestRegressor().fit(X_train,Y_train)\n",
    "print(\"RF: {:.2f}%\".format(predict_reg(model, X_test, Y_test)))\n",
    "print(\"####\")\n",
    "model = GradientBoostingRegressor().fit(X_train,Y_train)\n",
    "print(\"GBM: {:.2f}%\".format(predict_reg(model, X_test, Y_test)))\n",
    "print(\"####\")\n",
    "model = MLPRegressor(max_iter=1000,hidden_layer_sizes=(50,20)).fit(X_train, Y_train)\n",
    "print(\"NN: {:.2f}%\".format(predict_reg(model, X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dimelo_v2_modkit_parsing",
   "language": "python",
   "name": "dimelo_v2_modkit_parsing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
